{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex Polynomial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pystatplottools.pdf_env.loading_figure_mode import loading_figure_mode\n",
    "fma, plt = loading_figure_mode(develop=True) # develop=False will export the generated figures as pngs into \"./data/RectangleData\"\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "\n",
    "if 'root_dir' not in locals():\n",
    "    # Navigate to simulations/ComplexPolynomialModel directory as simulation root directory\n",
    "    import os\n",
    "    os.chdir(\"../simulations/ComplexPolynomialModel\")\n",
    "    root_dir = os.getcwd()\n",
    "\n",
    "# To be able to compute custom measures\n",
    "import sys\n",
    "sys.path.append(\"./../../python_scripts\")\n",
    "    \n",
    "mcmc_model_dir = \"ComplexPolynomialModelVaryingLambdaImag/\"\n",
    "mcmc_data_dir = root_dir + \"/data/\" + mcmc_model_dir\n",
    "mcmc_results_dir = root_dir + \"/results/\" + mcmc_model_dir\n",
    "\n",
    "data_dir = root_dir + \"/data/\" + mcmc_model_dir\n",
    "results_dir = root_dir + \"/results/\" + mcmc_model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simulation with a single Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcmctools.modes.expectation_value import load_expectation_value_results\n",
    "expectation_values = load_expectation_value_results(files_dir=\"ComplexPolynomialModelComplexLangevin\")\n",
    "expectation_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Evaluation with the pystatplottools Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of the Samples in the Complex Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "from mcmctools.loading.loading import load_data\n",
    "\n",
    "# skipcols=[] Can be used to load only certain columns of the different files\n",
    "data, filenames = load_data(files_dir=mcmc_model_dir, running_parameter=\"default\",\n",
    "                            identifier=\"expectation_value\")  # , skipcols=[\"Config\"])\n",
    "from mcmctools.utils.json import load_configs\n",
    "sim_params, execution_params, running_parameter = load_configs(\n",
    "    files_dir=mcmc_model_dir, mode=\"expectation_value\", project_base_dir=\"./\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_data = pd.DataFrame({\"real_part\": np.real(data[\"Config\"].values),\n",
    "                             \"imag_part\": np.imag(data[\"Config\"].values)})\n",
    "\n",
    "# Prepare for usage as a distribution\n",
    "from pystatplottools.utils.utils import add_index_level\n",
    "complex_data = add_index_level(complex_data)\n",
    "complex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystatplottools.distributions.joint_distribution import JointDistribution\n",
    "\n",
    "joint_distribution = JointDistribution(data=complex_data)\n",
    "\n",
    "range_min, range_max = joint_distribution.extract_min_max_range_values([\"real_part\", \"imag_part\"])\n",
    "\n",
    "joint_distribution.compute(\n",
    "    axes_indices=[\"real_part\", \"imag_part\"],\n",
    "    range_min=[-2.0, -0.6],\n",
    "    range_max=[2.0, 0.6],\n",
    "    nbins=[40, 40],\n",
    "    statistic=\"probability\"\n",
    ")\n",
    "\n",
    "# The histograms can be accessed via: joint_distribution.distribution or linearized.\n",
    "\n",
    "# Transforms joint_distribution into a linear list of mid boundaries for the different bins\n",
    "# and the respective statistics for the values\n",
    "linearized_joint_distribution = joint_distribution.linearize(\n",
    "    output_statistics_name=\"prob\",\n",
    "    dataframes_as_columns=False,\n",
    "    bin_alignment=\"center\" # Default\n",
    ")\n",
    "linearized_joint_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour plot\n",
    "fig, axes = fma.newfig(0.8, nrows=1, ncols=2, figsize=(14, 7))\n",
    "\n",
    "from pystatplottools.plotting.contour2D import Contour2D\n",
    "\n",
    "axes[0].scatter(complex_data[\"real_part\"][:10000], complex_data[\"imag_part\"][:10000], s=0.4)\n",
    "axes[0].set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "\n",
    "contour2D = Contour2D(\n",
    "    ax=axes[1],\n",
    "    data=linearized_joint_distribution.loc[\"df\"],\n",
    "    x=\"real_part\",\n",
    "    y=\"imag_part\",\n",
    "    z_index=\"prob\"\n",
    ")\n",
    "\n",
    "contour2D.set_ax_labels(x_label=\"x\", y_label=\"y\")\n",
    "cf = contour2D.contourf(\n",
    "    lev_num=40,\n",
    "    cbar_scale='Lin',\n",
    "    cmap=\"PiYG\"\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "\n",
    "cax = fig.add_axes([0.85, 0.1, 0.04, 0.75])\n",
    "# legend_ax.set_axis_off()\n",
    "\n",
    "# Add additional axes\n",
    "contour2D.add_colorbar(fig=fig, cf=cf, z_label=\"P(x, y)\", cax=cax)\n",
    "\n",
    "# plt.tight_layout()\n",
    "fma.savefig(results_dir, \"complex_distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations as Pytorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show how the mcmc configurations can be stored and loaded as a .pt file.\n",
    "\n",
    "(See also python_scripts/loading_configurations.py and python_scripts/pytorch_data_generation.py)\n",
    "\n",
    "Currently, this only works if a running_parameter has been defined. We therefore load the data from our second simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_args = {\n",
    "    # ConfigDataGenerator Args\n",
    "    \"data_type\": \"target_param\",\n",
    "    \"complex_config\": True,\n",
    "    # Args for ConfigurationLoader\n",
    "    \"path\": mcmc_data_dir,\n",
    "    \"total_number_of_data_per_file\": 100000,\n",
    "    \"identifier\": \"expectation_value\",\n",
    "    \"running_parameter\": \"lambda_imag\",\n",
    "    \"chunksize\": 400  # If no chunksize is given, all data is loaded at once\n",
    "}\n",
    "\n",
    "# Prepare in memory dataset\n",
    "from pystatplottools.pytorch_data_generation.data_generation.datagenerationroutines import prepare_in_memory_dataset\n",
    "from mcmctools.pytorch.data_generation.datagenerationroutines import data_generator_factory\n",
    "\n",
    "prepare_in_memory_dataset(\n",
    "    root=data_dir,\n",
    "    batch_size=128,\n",
    "    data_generator_args=data_generator_args,\n",
    "    data_generator_name=\"BatchConfigDataGenerator\",\n",
    "    data_generator_factory=data_generator_factory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in memory dataset\n",
    "from pystatplottools.pytorch_data_generation.data_generation.datagenerationroutines import load_in_memory_dataset\n",
    "\n",
    "# The dataset is generated and stored as a .pt file in the data_dir/data directory the first time this function is called. Otherwise the .pt is loaded.\n",
    "data_loader = load_in_memory_dataset(\n",
    "    root=data_dir, batch_size=128, data_generator_factory=data_generator_factory, slices=None, shuffle=True,\n",
    "    num_workers=0, rebuild=False\n",
    "    # sample_data_generator_name=\"ConfigDataGenerator\"  # optional: for a generation of new samples\n",
    ")\n",
    "\n",
    "# Load training data\n",
    "for batch_idx, batch in enumerate(data_loader):\n",
    "    data, target = batch\n",
    "    # print(batch_idx, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
